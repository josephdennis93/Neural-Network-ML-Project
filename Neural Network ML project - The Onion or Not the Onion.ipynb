{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network ML project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "A collection of article headlines from the satire newspaper The Onion and headlines from the satire-of-satire subreddit r/nottheonion. Data originally collected by reddit user u/333luke.\n",
    "#NOTE: Articles originally from the Onion are marked 1, and those from the subreddit are 0.\n",
    "\n",
    "The model appeared to overfit after the first few epochs, but still achieved ~83% accuracy when tested using the test data set (which is probably a lot better than many of the readers of these subreddits!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "sns.set()\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entire Facebook Staff Laughs As Man Tightens P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muslim Woman Denied Soda Can for Fear She Coul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bold Move: Hulu Has Announced That They’re Gon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despondent Jeff Bezos Realizes He’ll Have To W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For men looking for great single women, online...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Entire Facebook Staff Laughs As Man Tightens P...      1\n",
       "1  Muslim Woman Denied Soda Can for Fear She Coul...      0\n",
       "2  Bold Move: Hulu Has Announced That They’re Gon...      1\n",
       "3  Despondent Jeff Bezos Realizes He’ll Have To W...      1\n",
       "4  For men looking for great single women, online...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('OnionOrNot.csv') #1 = onion, 2=not onion\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rid of punctuation etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entire facebook staff laughs as man tightens p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muslim woman denied soda can for fear she coul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bold move hulu has announced that theyre gonna...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despondent jeff bezos realizes hell have to wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for men looking for great single women online ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  entire facebook staff laughs as man tightens p...      1\n",
       "1  muslim woman denied soda can for fear she coul...      0\n",
       "2  bold move hulu has announced that theyre gonna...      1\n",
       "3  despondent jeff bezos realizes hell have to wo...      1\n",
       "4  for men looking for great single women online ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_punk = raw_data.copy()\n",
    "\n",
    "data_no_punk['text'] = data_no_punk['text'].str.lower()\n",
    "data_no_punk['text'] = data_no_punk['text'].str.replace(r'&amp','and')\n",
    "data_no_punk['text'] = data_no_punk['text'].str.replace(r'-','')\n",
    "data_no_punk['text'] = data_no_punk['text'].str.replace(r'[^\\s\\w]','')\n",
    "#maybe drop articles in future, dunno how to write the code that won't gut other words tho\n",
    "\n",
    "data_no_punk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_punk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert words to dictionary and map words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()\n",
    "sentence_length = []\n",
    "\n",
    "for i in range(len(data_no_punk)):\n",
    "    sentence_words = re.split(r'\\s',data_no_punk.iloc[i]['text'])\n",
    "    vocab_set.update(sentence_words)\n",
    "    sentence_length.append(len(sentence_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(vocab_set)\n",
    "vocab_dict = {vocab_list[i-1]: i for i in range(1,len(vocab_list)+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(sentence_length)\n",
    "\n",
    "def toNumbers(row):\n",
    "    words = re.findall(r'([\\w]+)', row['text'])\n",
    "    nums =  np.array([vocab_dict[words[j]] for j in range(len(words))])\n",
    "    return np.pad(nums, (0, max_length - len(nums)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [6433, 14431, 5611, 5486, 24624, 19381, 12651,...\n",
       "1    [2263, 10071, 21918, 1821, 1547, 21085, 14043,...\n",
       "2    [26813, 9210, 942, 4754, 24893, 13836, 23810, ...\n",
       "3    [17005, 5570, 21566, 11499, 229, 6698, 24316, ...\n",
       "4    [21085, 5606, 6070, 21085, 14006, 6820, 13132,...\n",
       "Name: nums, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = data_no_punk.apply(lambda row: toNumbers(row), axis=1) \n",
    "data_no_punk['nums'] = nums\n",
    "\n",
    "data_no_punk['nums'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = data_no_punk.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entire facebook staff laughs as man tightens p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6433, 14431, 5611, 5486, 24624, 19381, 12651,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muslim woman denied soda can for fear she coul...</td>\n",
       "      <td>0</td>\n",
       "      <td>[2263, 10071, 21918, 1821, 1547, 21085, 14043,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bold move hulu has announced that theyre gonna...</td>\n",
       "      <td>1</td>\n",
       "      <td>[26813, 9210, 942, 4754, 24893, 13836, 23810, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despondent jeff bezos realizes hell have to wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[17005, 5570, 21566, 11499, 229, 6698, 24316, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for men looking for great single women online ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[21085, 5606, 6070, 21085, 14006, 6820, 13132,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  entire facebook staff laughs as man tightens p...      1   \n",
       "1  muslim woman denied soda can for fear she coul...      0   \n",
       "2  bold move hulu has announced that theyre gonna...      1   \n",
       "3  despondent jeff bezos realizes hell have to wo...      1   \n",
       "4  for men looking for great single women online ...      1   \n",
       "\n",
       "                                                nums  \n",
       "0  [6433, 14431, 5611, 5486, 24624, 19381, 12651,...  \n",
       "1  [2263, 10071, 21918, 1821, 1547, 21085, 14043,...  \n",
       "2  [26813, 9210, 942, 4754, 24893, 13836, 23810, ...  \n",
       "3  [17005, 5570, 21566, 11499, 229, 6698, 24316, ...  \n",
       "4  [21085, 5606, 6070, 21085, 14006, 6820, 13132,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data set into train, validation and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = data_preprocessed.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = tf.convert_to_tensor(data_preprocessed['nums'][:train_samples_count])\n",
    "train_targets = tf.convert_to_tensor(data_preprocessed['label'][:train_samples_count])\n",
    "\n",
    "validation_inputs = tf.convert_to_tensor(data_preprocessed['nums'][train_samples_count:train_samples_count+validation_samples_count])\n",
    "validation_targets = tf.convert_to_tensor(data_preprocessed['label'][train_samples_count:train_samples_count+validation_samples_count])\n",
    "\n",
    "test_inputs = tf.convert_to_tensor(data_preprocessed['nums'][train_samples_count+validation_samples_count:])\n",
    "test_targets = tf.convert_to_tensor(data_preprocessed['label'][train_samples_count+validation_samples_count:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7144 19200 0.3720833333333333\n",
      "924 2400 0.385\n",
      "932 2400 0.3883333333333333\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Onion_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Onion_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Onion_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19200 samples, validate on 2400 samples\n",
      "Epoch 1/100\n",
      "19200/19200 - 39s - loss: 0.4168 - accuracy: 0.8065 - val_loss: 0.3217 - val_accuracy: 0.8671\n",
      "Epoch 2/100\n",
      "19200/19200 - 33s - loss: 0.1674 - accuracy: 0.9394 - val_loss: 0.3711 - val_accuracy: 0.8658\n",
      "Epoch 3/100\n",
      "19200/19200 - 34s - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.5252 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2386cb99dc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_compiled_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(len(vocab_set)+1, 64),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)\n",
    "max_epochs = 100\n",
    "model = get_compiled_model()\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size=50,\n",
    "          epochs=max_epochs, \n",
    "          callbacks = [early_stopping],\n",
    "          validation_data = (validation_inputs,validation_targets),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 2s 982us/sample - loss: 0.5860 - accuracy: 0.8325\n",
      "\n",
      "Test loss: 0.59. Test accuracy: 83.25%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python 3 TF2.0]",
   "language": "python",
   "name": "conda-env-Python_3_TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
